---
widget: blank
headless: true

# ... Put Your Section Options Here (title etc.) ...
title: News
subtitle:
weight: 10  # section position on page
design:
  # Choose how many columns the section has. Valid values: 1 or 2.
  columns: '1'
---

- **June 2023:** We published the first paper from the [MLCommons' Algorithms working group](https://mlcommons.org/en/groups/research-algorithms/) on arXiv titled ["**Benchmarking Neural Network Training Algorithms**"](https://arxiv.org/abs/2306.07179).
  </br>*In it, we motivate, present, and justify our new AlgoPerf: Training Algorithms benchmark. We plan to issue a Call for Submissions for the benchmark soon.*
- **July 2022:** I succesfully defended my Ph.D. thesis with the title [**Understanding Deep Learning Optimization via Benchmarking and Debugging**](https://publikationen.uni-tuebingen.de/xmlui/handle/10900/131710)!
  </br>*I will continue to work as a postdoctoral researcher at the University of TÃ¼bingen.*
- **September 2021:** Our paper "**Cockpit: A Practical Debugging Tool for the Training of Deep Neural Networks**" has been accepted at [NeurIPS 2021](https://nips.cc/Conferences/2021/).
  </br>*In this work, we present a new kind of debugger, specifically designed for training deep nets.*
- **May 2021:** Our work "**Descending through a Crowded Valley - Benchmarking Deep Learning Optimziers**" has been accepted at [ICML 2021](https://icml.cc/Conferences/2021).
  </br>*In it, we present an extensive comparison of fifteen popular deep learning optimizers.*
- **April, 2021:** I have been elected as a co-chair for the [MLCommons](https://mlcommons.org/en/) working group on [Algorithmic Efficiency](https://mlcommons.org/en/groups/research-algorithms/) together with [George Dahl](https://www.cs.toronto.edu/~gdahl/).
  </br>*The working group will develop a set of rigorous and relevant benchmarks to measure training speedups to neural network training due to algorithmic improvements, focusing on new training algorithms and models.*
- **September & Oktober 2020:** I have been distinguished as a top reviewer for ICML 2020 and received a Top 10% Reviewer award for NeurIPS 2020.
- **May 2019:** Our paper "**DeepOBS: A Deep Learning Optimizer Benchmark Suite**" has been accepted at [ICLR 2019](https://iclr.cc/Conferences/2019).
  </br>*In the paper, we present a benchmark suite for deep learning optimization methods. I will be at the conference from 06th through 09th May in New Orleans, USA.*
